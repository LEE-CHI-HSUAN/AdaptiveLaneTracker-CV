{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from tools import readPredictions, getFrames, readLines, readImage, line_to_points\n",
    "\n",
    "pixel_thresh = 20\n",
    "pt_thresh = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_radian(xs, y_samples):\n",
    "    if len(xs) > 1:\n",
    "        slope, intercept = np.polyfit(xs, y_samples, 1)\n",
    "        theta = np.arctan(slope)\n",
    "    else:\n",
    "        theta = 0\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_accuracy(pred, gt, thresh) -> float:\n",
    "    '''\n",
    "    pred: predicted slope and intercept\n",
    "    gt: ground truth line = [(x1, y1), (x2, y2), ...]\n",
    "    return: a value between [0, 1]\n",
    "    '''\n",
    "    gt_xs = gt[0]\n",
    "    y_samples = gt[1]\n",
    "    pred_xs = line_to_points(*pred, y_samples[0], y_samples[-1])\n",
    "    # print(\"gt_xs\", gt_xs[:10])\n",
    "    # print(\"xs\", pred_xs[:10])\n",
    "    # print(f\"---{thresh = }, {len(y_samples) = }, {np.where(np.abs(gt_xs - pred_xs) < thresh, 1., 0.)[:10]}\")\n",
    "    return np.sum(np.where(np.abs(gt_xs - pred_xs) < thresh, 1., 0.)) / len(y_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_one_frame(pred, gt) -> list:\n",
    "    '''\n",
    "    pred: predicted lines = ((ls, li) (rs, ri))\n",
    "    gt: ground truth lines = [[(x1,x2,...), (y1,y2,...)], [...], ...]\n",
    "\n",
    "    return: a list of accuracy of and right prediction\n",
    "    '''\n",
    "    radians = [get_radian(lane[0], lane[1]) for lane in gt]\n",
    "    threshs = [pixel_thresh / np.abs(np.sin(radian)) for radian in radians]\n",
    "    line_accs = []\n",
    "    # fp, fn = 0., 0.\n",
    "    # matched = 0.\n",
    "    for pred_lane in pred:\n",
    "        accs = [line_accuracy(pred_lane, lane, thresh) for lane, thresh in zip(gt, threshs)]\n",
    "        # print(pred_lane, accs)\n",
    "        max_acc = np.max(accs) if len(accs) > 0 else 0.\n",
    "        # # fp fn will be removed\n",
    "        # if max_acc < pt_thresh:\n",
    "        #     fn += 1\n",
    "        # else:\n",
    "        #     matched += 1\n",
    "        line_accs.append(max_acc)\n",
    "    # fp = len(pred) - matched\n",
    "    # if len(gt) > 4 and fn > 0:\n",
    "    #     fn -= 1\n",
    "    return line_accs\n",
    "    s = sum(line_accs)\n",
    "    if len(gt) > 4:\n",
    "        s -= min(line_accs)\n",
    "    return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(min(len(gt), 4.) , 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawPredictions(img, predicted_lanes):\n",
    "    for predicted_lane in predicted_lanes:\n",
    "        lane_points = line_to_points(*predicted_lane, 300, 590, x_only=False).astype(np.int32)\n",
    "        for point in lane_points:\n",
    "            cv2.circle(img, point, 3, (0, 0, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_one_video(pred_file: str, gt_dir: Path, show: bool = False, wait_time: int = 0):\n",
    "    predReader = readPredictions(pred_file)\n",
    "    #accuracy, fp, fn = 0., 0., 0.\n",
    "    accuracy = []\n",
    "\n",
    "    frameNames = getFrames(str(gt_dir))\n",
    "    for frameName in frameNames:\n",
    "        pred_lanes = np.array(next(predReader))\n",
    "        gt_lanes = [np.array(line).T for line in readLines(str(gt_dir / (frameName[:-4] + \".lines.txt\")))]\n",
    "        a = bench_one_frame(pred_lanes, gt_lanes)\n",
    "        accuracy += a\n",
    "        \n",
    "        if show:\n",
    "            img = readImage(str(gt_dir / frameName), annotation=True)\n",
    "            drawPredictions(img, pred_lanes)\n",
    "            cv2.putText(img, f\"{a[0]:.2f}\", (400, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2)\n",
    "            cv2.putText(img, f\"{a[1]:.2f}\", (1000, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2)\n",
    "            cv2.imshow(\"judge\", img)\n",
    "            time.sleep(0.5)\n",
    "            if cv2.waitKey(wait_time) & 0xFF == ord('q'):\n",
    "                break\n",
    "        # accuracy += a\n",
    "        # fp += p\n",
    "        # fn += n\n",
    "    # num = len(gts)\n",
    "    # # the first return parameter is the default ranking parameter\n",
    "    # return json.dumps([\n",
    "    #     {'name': 'Accuracy', 'value': accuracy / num, 'order': 'desc'},\n",
    "    #     {'name': 'FP', 'value': fp / num, 'order': 'asc'},\n",
    "    #     {'name': 'FN', 'value': fn / num, 'order': 'asc'}\n",
    "    # ])\n",
    "    cv2.destroyAllWindows()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_a_list_of_video(pred_dir: str, video_list: str, show: bool = False):\n",
    "    '''\n",
    "    ## Parameters\n",
    "    `pred_dir`: the directory containing prediction files.\n",
    "    `video_list`: the text file containg the paths of .MP4 directories.\n",
    "    `show`: whether to visualize judging process.\n",
    "    '''\n",
    "    pred_dir = Path(pred_dir)\n",
    "    videoDirs = []\n",
    "    with open(video_list, \"r\") as fin:\n",
    "        for line in fin:\n",
    "            videoDirs.append(Path(line.strip()))\n",
    "    \n",
    "    accuaracy = []\n",
    "    for videoDir in videoDirs:\n",
    "        pred_file = str(pred_dir / (videoDir.name + \".prediction.txt\"))\n",
    "        print(pred_file)\n",
    "        accuaracy += bench_one_video(pred_file, videoDir, show)\n",
    "    \n",
    "    accuaracy = np.array(accuaracy[10:])\n",
    "    total_lines = len(accuaracy)\n",
    "    good_line_number = np.sum(np.where(accuaracy > pt_thresh, 1, 0))\n",
    "    print(f\"well detected lines: {good_line_number / total_lines}% ({good_line_number}/{total_lines})\")\n",
    "    return np.average(accuaracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dir = r\"..\\prediction\"\n",
    "video_list = r\"..\\video_list.txt\"\n",
    "bench_a_list_of_video(pred_dir, video_list, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_to_points(1, 1, 50, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dir = r\"..\\prediction\"\n",
    "video_list = r\"..\\video_list2.txt\"\n",
    "bench_a_list_of_video(pred_dir, video_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
